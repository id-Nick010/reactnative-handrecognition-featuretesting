## Feature Testing React Native Environment for Hand Sign Recognition using Mediapipe & TFLite Model

This project tests a Hand Sign Recognition System using Mediapipe and TensorFlow Lite (TFLite) models within a React Native environment. It aims to evaluate the feasibility of real-time gesture recognition for mobile applications.

### Features
- Robust hand tracking with Mediapipe.
- Lightweight inference via TFLite models.
- Optimized for real-time performance on mobile devices.

### Task
- [x] TFLite Model Loader Module 
- [x] Vision Camera Feature & Permission Handling Module
- [ ] Mediapipe Landmark Point Extraction Module
- [ ] Landmark Data Preprocessing Module
- [ ] Model Prediction Algorithm Module

### Purpose
The primary goal of this project is to test the viability and performance of deploying a hand sign recognition system using React Native. This serves as a foundational step for developing intuitive and accessible applications powered by machine learning.